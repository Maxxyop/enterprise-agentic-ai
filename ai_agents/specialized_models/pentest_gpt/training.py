import torch # type: ignore
from torch import nn # type: ignore
from torch.utils.data import DataLoader # type: ignore
from transformers import AdamW, get_linear_schedule_with_warmup # type: ignore
from .inference import PentestGPTInference
from .dataset import PentestGPTDataset # type: ignore

class PentestGPTTrainer:
    def __init__(self, model, train_dataset, val_dataset, config):
        self.model = model
        self.train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)
        self.val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)
        self.optimizer = AdamW(self.model.parameters(), lr=config['learning_rate'])
        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, 
                                                          num_warmup_steps=config['warmup_steps'], 
                                                          num_training_steps=len(self.train_loader) * config['num_epochs'])
        self.criterion = nn.CrossEntropyLoss()
        self.inference = PentestGPTInference(model)

    def train(self, num_epochs):
        for epoch in range(num_epochs):
            self.model.train()
            total_loss = 0
            for batch in self.train_loader:
                inputs, labels = batch
                self.optimizer.zero_grad()
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                loss.backward()
                self.optimizer.step()
                self.scheduler.step()
                total_loss += loss.item()
            avg_loss = total_loss / len(self.train_loader)
            print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}")
            self.validate()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch
                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)
                total_loss += loss.item()
        avg_loss = total_loss / len(self.val_loader)
        print(f"Validation Loss: {avg_loss:.4f}")

    def save_model(self, path):
        torch.save(self.model.state_dict(), path)