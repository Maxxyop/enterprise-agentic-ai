import logging
from typing import Dict, Any, Optional
from ai_agents.foundation_models.llm_interface import LLMFactory
from pathlib import Path
import json

logger = logging.getLogger(__name__)

class VulnerabilityAnalyzer:
    """Analyzes tool outputs to identify vulnerabilities using DeepSeek R1."""
    
    def __init__(self, llm_factory: LLMFactory, prompt_dir: str = "prompt_engineering/templates"):
        self.llm_factory = llm_factory
        self.prompt_dir = Path(prompt_dir)
        self.prompt_templates = self._load_templates()
        
    def _load_templates(self) -> Dict[str, str]:
        """Load vulnerability analysis prompt templates from JSON files."""
        templates = {}
        template_files = ["nmap_analysis.json", "zap_analysis.json", "sqlmap_analysis.json"]
        try:
            for file in template_files:
                file_path = self.prompt_dir / file
                if file_path.exists():
                    with open(file_path, "r") as f:
                        templates[file] = json.load(f)["prompt"]
                else:
                    logger.warning(f"Template file {file} not found")
            return templates
        except Exception as e:
            logger.error(f"Failed to load analysis templates: {e}")
            return {}
    
    async def analyze_output(self, tool: str, output: str, target: str) -> Optional[Dict[str, Any]]:
        """Analyze tool output to identify vulnerabilities."""
        try:
            deepseek_client = self.llm_factory.get_client("vulnerability_analysis")
            template_key = f"{tool.lower()}_analysis.json"
            prompt_template = self.prompt_templates.get(
                template_key,
                "Analyze {tool} output for {target}: {output}. Identify vulnerabilities and suggest next steps."
            )
            prompt = prompt_template.format(tool=tool, target=target, output=output)
            analysis = await deepseek_client.generate(prompt, max_tokens=500)
            logger.debug(f"Analyzed {tool} output for {target}")
            return json.loads(analysis) if analysis else None
        except Exception as e:
            logger.error(f"Failed to analyze {tool} output: {e}")
            return None

async def main():
    """Example usage of VulnerabilityAnalyzer."""
    llm_factory = LLMFactory()
    analyzer = VulnerabilityAnalyzer(llm_factory)
    analysis = await analyzer.analyze_output(
        tool="zap",
        output="Alert: XSS found on shop.example.com/login",
        target="shop.example.com"
    )
    print(f"Vulnerability Analysis: {analysis}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())